{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a2f9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp paddle_ocr.ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e807350",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tempfile\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "_PADDLE_OCR = None\n",
    "\n",
    "# Standard angles for snapping\n",
    "STANDARD_ANGLES = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "SNAP_TOLERANCE = 20\n",
    "\n",
    "\n",
    "def _load_ocr():  \n",
    "    global _PADDLE_OCR  \n",
    "    if _PADDLE_OCR is not None:  \n",
    "        return _PADDLE_OCR  \n",
    "    try:  \n",
    "        from paddleocr import PaddleOCR  \n",
    "        _PADDLE_OCR = PaddleOCR(  \n",
    "            text_detection_model_dir=\"./weights/paddleocr/PP-OCRv5_server_det_infer\",  \n",
    "            text_recognition_model_dir=\"./weights/paddleocr/PP-OCRv5_server_rec_infer\",  \n",
    "            textline_orientation_model_dir=\"weights/paddleocr/PP-LCNet_x1_0_textline_ori_infer\",\n",
    "            use_doc_orientation_classify=False,  \n",
    "            use_doc_unwarping=False,  \n",
    "            use_textline_orientation=True,  # Enabled for orientation extraction\n",
    "            lang='en'  \n",
    "        )  \n",
    "        return _PADDLE_OCR  \n",
    "    except Exception as exc:    \n",
    "        print(f\"[PaddleOCR] Failed to initialize: {exc}\")  \n",
    "        _PADDLE_OCR = None  \n",
    "        return None\n",
    "\n",
    "\n",
    "def _flatten_poly(polygon) -> np.ndarray:\n",
    "    \"\"\"Flatten nested polygon into Nx2 array\"\"\"\n",
    "    arr = np.array(polygon, dtype=float)\n",
    "    if arr.ndim == 1:\n",
    "        arr = arr.reshape(-1, 2)\n",
    "    elif arr.ndim > 2:\n",
    "        arr = arr.reshape(-1, 2)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def calculate_rotation_from_polygon(polygon) -> float:\n",
    "    \"\"\"Calculate rotation angle from text polygon using PCA/SVD.\"\"\"\n",
    "    pts = _flatten_poly(polygon)\n",
    "    n = pts.shape[0]\n",
    "\n",
    "    if n < 2:\n",
    "        return 0.0\n",
    "\n",
    "    if n == 2:\n",
    "        dx = pts[1, 0] - pts[0, 0]\n",
    "        dy = pts[1, 1] - pts[0, 1]\n",
    "        return (math.degrees(math.atan2(-dy, dx)) + 360) % 360\n",
    "\n",
    "    centered = pts - pts.mean(axis=0)\n",
    "\n",
    "    if np.allclose(centered, 0, atol=1e-6):\n",
    "        return 0.0\n",
    "\n",
    "    _, _, Vt = np.linalg.svd(centered, full_matrices=False)\n",
    "    vx, vy = Vt[0]\n",
    "    pca_angle = (math.degrees(math.atan2(-vy, vx)) + 360) % 360\n",
    "\n",
    "    x = pts[:, 0]\n",
    "    y = pts[:, 1]\n",
    "    if len(np.unique(x)) > 1:\n",
    "        a, b = np.polyfit(x, y, 1)\n",
    "        lf_angle = (math.degrees(math.atan2(-a, 1)) + 360) % 360\n",
    "    else:\n",
    "        lf_angle = pca_angle\n",
    "\n",
    "    pca_var = np.var(centered @ np.array([vx, vy]))\n",
    "    lf_dir = np.array([1, a]) / np.linalg.norm([1, a]) if len(np.unique(x)) > 1 else np.array([1, 0])\n",
    "    lf_var = np.var(centered @ lf_dir)\n",
    "\n",
    "    best = pca_angle if pca_var >= lf_var else lf_angle\n",
    "    return round(best, 2)\n",
    "\n",
    "\n",
    "def snap_to_standard_angle(angle: float, tolerance: int = SNAP_TOLERANCE) -> float:\n",
    "    \"\"\"Snap angle to nearest standard angle if within tolerance.\"\"\"\n",
    "    angle = angle % 360\n",
    "    best = min(STANDARD_ANGLES, key=lambda s: abs(angle - s))\n",
    "    return float(best) if abs(best - angle) <= tolerance else round(angle, 1)\n",
    "\n",
    "\n",
    "def _preprocess_for_ocr(image_bgr: np.ndarray) -> np.ndarray:\n",
    "    kernel = np.array([[0, -1, 0], [-1, 3, -1], [0, -1, 0]])\n",
    "    sharpened = cv2.filter2D(image_bgr, -1, kernel)\n",
    "    alpha = 0.5\n",
    "    blended = cv2.addWeighted(image_bgr, 1 - alpha, sharpened, alpha, 0)\n",
    "    return blended\n",
    "\n",
    "\n",
    "def extract_text(file_path: str) -> List[Dict[str, Tuple[int, int, int, int]]]:\n",
    "    \"\"\"Run PaddleOCR and return list of {text, confidence, bbox(x1,y1,x2,y2)}\"\"\"\n",
    "\n",
    "    # Set confidence threshold to filter low-confidence OCR results\n",
    "    min_confidence = 0.4\n",
    "\n",
    "    ocr = _load_ocr()\n",
    "    if ocr is None:\n",
    "        return []\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return []\n",
    "\n",
    "    image_bgr = cv2.imread(file_path)\n",
    "    if image_bgr is None:\n",
    "        return []\n",
    "\n",
    "    image_bgr = _preprocess_for_ocr(image_bgr)\n",
    "\n",
    "    try:\n",
    "        result = ocr.predict(image_bgr)\n",
    "        outputs: List[Dict] = []\n",
    "        if not result:\n",
    "            return outputs\n",
    "        # Persist first result to JSON for stable parsing\n",
    "        tmp_dir = tempfile.gettempdir()\n",
    "        tmp_json = os.path.join(tmp_dir, \"paddle_ocr_result.json\")\n",
    "        try:\n",
    "            first = result[0]\n",
    "            # Some versions expose .save_to_json, others not\n",
    "            if hasattr(first, \"save_to_json\"):\n",
    "                first.save_to_json(tmp_json)\n",
    "            else:\n",
    "                # Try to serialize via .res\n",
    "                if hasattr(first, \"res\") and isinstance(first.res, dict):\n",
    "                    with open(tmp_json, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump(first.res, f)\n",
    "                else:\n",
    "                    tmp_json = None\n",
    "        except Exception:\n",
    "            tmp_json = None\n",
    "\n",
    "        if tmp_json and os.path.exists(tmp_json):\n",
    "            try:\n",
    "                with open(tmp_json, \"r\", encoding=\"utf-8\") as f:\n",
    "                    ocr_json = json.load(f)\n",
    "                rec_texts = ocr_json.get(\"rec_texts\", [])\n",
    "                rec_scores = ocr_json.get(\"rec_scores\", [])\n",
    "                rec_polys = ocr_json.get(\"rec_polys\", [])\n",
    "                orientation_angles = ocr_json.get(\"textline_orientation_angles\", [])\n",
    "\n",
    "                for i, (text, score, poly) in enumerate(zip(rec_texts, rec_scores, rec_polys)):\n",
    "                    # Apply confidence threshold filter\n",
    "                    if float(score) < min_confidence:\n",
    "                        continue\n",
    "                    pts = _flatten_poly(poly)\n",
    "                    x1, y1 = np.min(pts, axis=0)\n",
    "                    x2, y2 = np.max(pts, axis=0)\n",
    "\n",
    "                    # Calculate rotation from polygon\n",
    "                    raw_rotation = calculate_rotation_from_polygon(poly)\n",
    "                    snapped_rotation = snap_to_standard_angle(raw_rotation)\n",
    "\n",
    "                    outputs.append({\n",
    "                        \"text\": str(text),\n",
    "                        \"confidence\": float(score),\n",
    "                        \"bbox\": (int(x1), int(y1), int(x2), int(y2)),\n",
    "                        \"polygon\": poly,\n",
    "                        \"paddleocr_orientation\": orientation_angles[i] if i < len(orientation_angles) else None,\n",
    "                        \"polygon_rotation\": raw_rotation,\n",
    "                        \"shape_rotation\": snapped_rotation\n",
    "                    })\n",
    "                return outputs\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            first = result[0]\n",
    "            rec_texts = first.res.get(\"rec_texts\") if hasattr(first, \"res\") else None\n",
    "            rec_scores = first.res.get(\"rec_scores\") if hasattr(first, \"res\") else None\n",
    "            rec_polys = first.res.get(\"rec_polys\") if hasattr(first, \"res\") else None\n",
    "            orientation_angles = first.res.get(\"textline_orientation_angles\", []) if hasattr(first, \"res\") else []\n",
    "            if rec_texts is None or rec_scores is None or rec_polys is None:\n",
    "                return outputs\n",
    "            for i, (text, score, poly) in enumerate(zip(rec_texts, rec_scores, rec_polys)):\n",
    "                # Apply confidence threshold filter\n",
    "                if float(score) < min_confidence:\n",
    "                    continue\n",
    "                pts = _flatten_poly(poly)\n",
    "                x1, y1 = np.min(pts, axis=0)\n",
    "                x2, y2 = np.max(pts, axis=0)\n",
    "\n",
    "                # Calculate rotation from polygon\n",
    "                raw_rotation = calculate_rotation_from_polygon(poly)\n",
    "                snapped_rotation = snap_to_standard_angle(raw_rotation)\n",
    "\n",
    "                outputs.append({\n",
    "                    \"text\": str(text),\n",
    "                    \"confidence\": float(score),\n",
    "                    \"bbox\": (int(x1), int(y1), int(x2), int(y2)),\n",
    "                    \"polygon\": poly,\n",
    "                    \"paddleocr_orientation\": orientation_angles[i] if i < len(orientation_angles) else None,\n",
    "                    \"polygon_rotation\": raw_rotation,\n",
    "                    \"shape_rotation\": snapped_rotation\n",
    "                })\n",
    "            return outputs\n",
    "        except Exception:\n",
    "            return outputs\n",
    "    except Exception as exc:  \n",
    "        print(f\"[PaddleOCR] Inference failed: {exc}\")\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
